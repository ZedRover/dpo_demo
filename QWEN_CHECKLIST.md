# Qwen3-8B è®­ç»ƒå‰æ£€æŸ¥æ¸…å•

åœ¨æäº¤ SLURM ä»»åŠ¡å‰,è¯·ç¡®è®¤ä»¥ä¸‹äº‹é¡¹:

## âœ… ç¯å¢ƒå‡†å¤‡

- [ ] Python ç¯å¢ƒå·²é…ç½® (`uv sync` å®Œæˆ)
- [ ] CUDA å¯ç”¨ (`nvidia-smi` æ­£å¸¸)
- [ ] å­˜å‚¨ç©ºé—´å……è¶³ (>100GB å¯ç”¨)
- [ ] logs ç›®å½•å­˜åœ¨ (`mkdir -p logs`)

## âœ… GPU èµ„æº

- [ ] ç¡®è®¤ GPU å‹å·å’Œæ˜¾å­˜
  ```bash
  nvidia-smi --query-gpu=name,memory.total --format=csv
  ```
- [ ] æ ¹æ®æ˜¾å­˜è°ƒæ•´æ‰¹æ¬¡å¤§å°:
  - 24GB â†’ batch_size=1-2, load_in_8bit=true
  - 40GB â†’ batch_size=4-8
  - 80GB â†’ batch_size=8-16

## âœ… æ¨¡å‹è®¿é—®

- [ ] ç¡®è®¤å¯ä»¥è®¿é—® Hugging Face
  ```bash
  python -c "from transformers import AutoTokenizer; AutoTokenizer.from_pretrained('Qwen/Qwen3-8B')"
  ```
- [ ] å¦‚åœ¨ä¸­å›½,è®¾ç½®é•œåƒ:
  ```bash
  export HF_ENDPOINT=https://hf-mirror.com
  ```

## âœ… æ•°æ®é›†

- [ ] ç¡®è®¤å¯ä»¥ä¸‹è½½ Anthropic/hh-rlhf
  ```bash
  python -c "from datasets import load_dataset; load_dataset('Anthropic/hh-rlhf', split='train[:10]')"
  ```

## âœ… SLURM é…ç½®

æ£€æŸ¥è„šæœ¬ä¸­çš„é…ç½®æ˜¯å¦ç¬¦åˆä½ çš„é›†ç¾¤:

- [ ] `#SBATCH --partition=gpu` - åˆ†åŒºåç§°æ­£ç¡®
- [ ] `#SBATCH --gres=gpu:1` - GPU è¯·æ±‚æ ¼å¼æ­£ç¡®
- [ ] `#SBATCH --time=48:00:00` - æ—¶é—´é™åˆ¶è¶³å¤Ÿä¸”ä¸è¶…è¿‡åˆ†åŒºé™åˆ¶
- [ ] `#SBATCH --mem=64G` - å†…å­˜è¯·æ±‚ä¸è¶…è¿‡èŠ‚ç‚¹é™åˆ¶
- [ ] æ¨¡å—åŠ è½½å‘½ä»¤æ­£ç¡® (å¦‚éœ€è¦)

æŸ¥çœ‹é›†ç¾¤é…ç½®:
```bash
sinfo -o "%20P %5a %10l %16F"
```

## âœ… å¿«é€Ÿæµ‹è¯• (å¼ºçƒˆæ¨è!)

åœ¨å®Œæ•´è®­ç»ƒå‰è¿è¡Œæµ‹è¯•:

```bash
sbatch slurm_qwen_8b_test.sh
```

ç­‰å¾…æµ‹è¯•å®Œæˆ (~30åˆ†é’Ÿ),ç¡®è®¤:
- [ ] æ¨¡å‹æˆåŠŸåŠ è½½
- [ ] è®­ç»ƒæ­£å¸¸è¿è¡Œ
- [ ] GPU å†…å­˜å……è¶³
- [ ] æ—¥å¿—è¾“å‡ºæ­£å¸¸

## âœ… å®Œæ•´è®­ç»ƒå‡†å¤‡

æµ‹è¯•é€šè¿‡å:

- [ ] æ£€æŸ¥è¶…å‚æ•°è®¾ç½®
  - BETA=0.1 (DPO æ¸©åº¦)
  - LEARNING_RATE=5e-7 (å­¦ä¹ ç‡)
  - MAX_STEPS=10000 (è®­ç»ƒæ­¥æ•°)

- [ ] è®¾ç½®è¾“å‡ºç›®å½•
  - ç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´å­˜å‚¨æ£€æŸ¥ç‚¹

- [ ] (å¯é€‰) é…ç½® W&B
  ```bash
  export WANDB_API_KEY="your_key"
  ```

## âœ… æäº¤ä»»åŠ¡

ä¸€åˆ‡å‡†å¤‡å°±ç»ªå:

```bash
sbatch slurm_qwen_8b.sh
```

è®°å½•ä»»åŠ¡ ID:
```bash
JOB_ID=<your_job_id>
```

## âœ… ç›‘æ§è®­ç»ƒ

- [ ] æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€
  ```bash
  squeue -u $USER
  ```

- [ ] ç›‘æ§æ—¥å¿—
  ```bash
  tail -f logs/dpo_qwen_${JOB_ID}.out
  ```

- [ ] æ£€æŸ¥ GPU åˆ©ç”¨ç‡ (å¦‚æœå¯ä»¥ SSH åˆ°è®¡ç®—èŠ‚ç‚¹)
  ```bash
  watch -n 5 nvidia-smi
  ```

## ğŸš¨ å¸¸è§é—®é¢˜å¿«é€Ÿä¿®å¤

### OOM (æ˜¾å­˜ä¸è¶³)

```bash
# ç¼–è¾‘ slurm_qwen_8b.sh
BATCH_SIZE=1
LOAD_IN_8BIT=true
MAX_LENGTH=256
```

### ä»»åŠ¡ä¸€ç›´åœ¨æ’é˜Ÿ

```bash
# æ£€æŸ¥é˜Ÿåˆ—æƒ…å†µ
squeue -p gpu

# æŸ¥çœ‹ä½ çš„ä»»åŠ¡ä¼˜å…ˆçº§
sprio -j <JOB_ID>
```

### æ¨¡å‹ä¸‹è½½å¤±è´¥

```bash
# é¢„å…ˆä¸‹è½½æ¨¡å‹
srun --gres=gpu:1 --pty bash
python -c "
from transformers import AutoModelForCausalLM, AutoTokenizer
AutoModelForCausalLM.from_pretrained('Qwen/Qwen3-8B')
"
```

## ğŸ“Š è®­ç»ƒå®Œæˆå

- [ ] æ£€æŸ¥æœ€ç»ˆæ¨¡å‹
  ```bash
  ls -lh outputs/qwen2.5_8b_*/final_model/
  ```

- [ ] ç”Ÿæˆå¯è§†åŒ–
  ```bash
  uv run python visualize.py --tracker_path outputs/qwen2.5_8b_*/reward_kl_tracker.json
  ```

- [ ] è¯„ä¼°æ¨¡å‹
  ```bash
  uv run python evaluate.py --model_path outputs/qwen2.5_8b_*/final_model
  ```

## ğŸ¯ é¢„æœŸè®­ç»ƒæ—¶é—´

| GPU | æ‰¹æ¬¡å¤§å° | é¢„è®¡æ—¶é—´ (10K steps) |
|-----|---------|---------------------|
| A100-80GB | 8 | ~12-16å°æ—¶ |
| A100-40GB | 4 | ~16-20å°æ—¶ |
| V100-32GB | 2 | ~30-36å°æ—¶ |
| RTX 3090 | 1 (8bit) | ~40-48å°æ—¶ |

## ğŸ“ è®°å½•ä¿¡æ¯

è®­ç»ƒä»»åŠ¡ä¿¡æ¯:
```
ä»»åŠ¡ ID: _________________
å¼€å§‹æ—¶é—´: _________________
é¢„è®¡å®Œæˆ: _________________
GPU å‹å·: _________________
æ‰¹æ¬¡å¤§å°: _________________
å­¦ä¹ ç‡: _________________
å…¶ä»–å¤‡æ³¨: _________________
```

---

**å‡†å¤‡å¥½äº†å—?** å¦‚æœæ‰€æœ‰å¤é€‰æ¡†éƒ½å·²å‹¾é€‰,è¿è¡Œ:

```bash
sbatch slurm_qwen_8b.sh
```

ç¥è®­ç»ƒé¡ºåˆ©! ğŸš€
